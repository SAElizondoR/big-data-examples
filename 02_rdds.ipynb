{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el entorno de Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext, StorageLevel\n",
    "import random\n",
    "import time\n",
    "import multiprocessing\n",
    "import requests\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de Spark\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"MiAplicaciónModificada\") \\\n",
    "    .set(\"spark.master\", \"local[10]\") \\\n",
    "    .set(\"spark.executor.cores\", \"2\") \\\n",
    "    .set(\"spark.executor.memory\", \"2g\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado en mayúsculas: ['B', 'A', 'C']\n"
     ]
    }
   ],
   "source": [
    "# Función para transformar una lista de letras a mayúsculas\n",
    "def transformar_a_mayusculas(lista):\n",
    "    rdd = sc.parallelize(lista)\n",
    "    return rdd.map(str.upper).collect()\n",
    "\n",
    "# Crear un RDD y transformarlo\n",
    "lista = ['b', 'a', 'c']\n",
    "resultado_letras = transformar_a_mayusculas(lista)\n",
    "print(\"Resultado en mayúsculas:\", resultado_letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado multiplicado: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
      "Tipo de resultado: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Función para multiplicar por 2 cada número de una lista\n",
    "def multiplicar_por_dos(datos):\n",
    "    rdd = sc.parallelize(datos)\n",
    "    return rdd.map(lambda x: x * 2).collect()\n",
    "\n",
    "# Crear un RDD de números y multiplicar por dos\n",
    "numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "resultado_numeros = multiplicar_por_dos(numeros)\n",
    "print(\"Resultado multiplicado:\", resultado_numeros)\n",
    "\n",
    "# Verificar el tipo de resultado\n",
    "print(\"Tipo de resultado:\", type(resultado_numeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz generada: [[44, 39, 27, 97, 48], [71, 56, 43], [99, 1], [], [89], [35, 91, 41]]\n"
     ]
    }
   ],
   "source": [
    "# Función para generar una matriz aleatoria\n",
    "def generar_matriz(filas, max_columnas, valor_maximo):\n",
    "    return [\n",
    "        [random.randint(1, valor_maximo)\n",
    "            for _ in range(random.randint(0, max_columnas))]\n",
    "        for _ in range(filas)\n",
    "    ]\n",
    "\n",
    "# Generar una matriz de 6 filas, con un máximo de 5 columnas y valores entre\n",
    "# 1 y 100\n",
    "matriz = generar_matriz(6, 5, 100)\n",
    "print(\"Matriz generada:\", matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado aplanado: [44, 39, 27, 97, 48, 71, 56, 43, 99, 1, 89, 35, 91, 41]\n"
     ]
    }
   ],
   "source": [
    "# Convertir matriz en RDD y aplanar sus elementos\n",
    "rdd_matriz = sc.parallelize(matriz)\n",
    "resultado_aplanado = rdd_matriz.flatMap(lambda x: x).collect()\n",
    "print(\"Resultado aplanado:\", resultado_aplanado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Números aleatorios: [97, 99, 94, 2, 51, 81, 62, 80, 83, 94]\n",
      "Múltiplos de 5: [80]\n"
     ]
    }
   ],
   "source": [
    "# Crear un RDD de números aleatorios y filtrar los múltiplos de 5\n",
    "x = sc.parallelize([random.randint(1, 100) for _ in range(10)])\n",
    "y = x.filter(lambda num: num % 5 == 0)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Números aleatorios:\", x.collect())\n",
    "print(\"Múltiplos de 5:\", y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado filtrado: [6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Realizar transformaciones a una lista de listas\n",
    "datos = [[1, 2], [3, 4, 5], []]\n",
    "rdd = sc.parallelize(datos)\n",
    "\n",
    "# Aplanar la lista y multiplicar por 2\n",
    "rdd_aplanado = rdd.flatMap(lambda x: x)\n",
    "rdd2 = rdd_aplanado.map(lambda x: x * 2)\n",
    "\n",
    "# Obtener sólo los resultados mayores a 5\n",
    "rdd_filtrado = rdd2.filter(lambda x: x > 5)\n",
    "\n",
    "# Obtener el resultado final\n",
    "resultado = rdd_filtrado.collect()\n",
    "print(\"Resultado filtrado:\", resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado agrupado: [('fruta', ['melón', 'arándano', 'naranja', 'tomate', 'limón']), ('verdura', ['acelga', 'apio', 'lechuga'])]\n",
      "Frutas: ('fruta', ['melón', 'arándano', 'naranja', 'tomate', 'limón'])\n",
      "Resultado como mapa: {'fruta': ['melón', 'arándano', 'naranja', 'tomate', 'limón'], 'verdura': ['acelga', 'apio', 'lechuga']}\n",
      "Frutas desde mapa: ['melón', 'arándano', 'naranja', 'tomate', 'limón']\n"
     ]
    }
   ],
   "source": [
    "# Agrupación de datos por clave\n",
    "rdd = sc.parallelize([\n",
    "    ('fruta', 'melón'),\n",
    "    ('verdura', 'acelga'),\n",
    "    ('fruta', 'arándano'),\n",
    "    ('fruta', 'naranja'),\n",
    "    ('verdura', 'apio'),\n",
    "    ('verdura', 'lechuga'),\n",
    "    ('fruta', 'tomate'),\n",
    "    ('fruta', 'limón')\n",
    "])\n",
    "\n",
    "# Agrupar por clave\n",
    "rdd_agrupado = rdd.groupByKey()\n",
    "\n",
    "# Convertir a lista\n",
    "rdd_lista = rdd_agrupado.mapValues(list)\n",
    "resultado = rdd_lista.collect()\n",
    "print(\"Resultado agrupado:\", resultado)\n",
    "\n",
    "# Primer resultado\n",
    "print(\"Frutas:\", resultado[0])\n",
    "\n",
    "# Convertir a mapa y acceder a valores\n",
    "resultado_mapa = rdd_lista.collectAsMap()\n",
    "print(\"Resultado como mapa:\", resultado_mapa)\n",
    "print(\"Frutas desde mapa:\", resultado_mapa['fruta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma por clave: {'frutas': 13, 'vegetales': 9}\n",
      "Máximo por clave: {'frutas': 7, 'vegetales': 5}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de reducción: Sumar valores por clave\n",
    "rdd = sc.parallelize([\n",
    "    (\"frutas\", 2),\n",
    "    (\"frutas\", 3),\n",
    "    (\"vegetales\", 4),\n",
    "    (\"frutas\", 1),\n",
    "    (\"vegetales\", 5),\n",
    "    (\"frutas\", 7)\n",
    "])\n",
    "\n",
    "# Sumar y encontrar el máximo valor por clave\n",
    "suma_por_clave = rdd.reduceByKey(lambda x, y: x + y).collectAsMap()\n",
    "maximo_por_clave = rdd.reduceByKey(max).collectAsMap()\n",
    "\n",
    "print(\"Suma por clave:\", suma_por_clave)\n",
    "print(\"Máximo por clave:\", maximo_por_clave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera acción; Se calcula el RDD: [2, 4, 6, 8, 10]\n",
      "Segunda acción; Ya con los datos en la memoria intermedia: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de almacenamiento en la memoria intermedia: Transformaciones en RDD\n",
    "rdd_transformado = sc.parallelize([1, 2, 3, 4, 5]).map(lambda x: x * 2)\n",
    "print(\"Primera acción; Se calcula el RDD:\", rdd_transformado.collect())\n",
    "\n",
    "rdd_transformado.cache()  # Almacenar en memoria el RDD transformado\n",
    "print(\"Segunda acción; Ya con los datos en la memoria intermedia:\",\n",
    "    rdd_transformado.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medición de tiempos de ejecución\n",
    "datos = [1, 2, 3, 4, 5] * 1_000_000\n",
    "rdd = sc.parallelize(datos)\n",
    "\n",
    "# Definir la transformación\n",
    "def transformation(x):\n",
    "    return x * random.randint(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/06 18:59:16 WARN TaskSetManager: Stage 35 contains a task of very large size (9908 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo sin memoria: 2.9843223094940186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tiempo sin memoria\n",
    "inicio = time.time()\n",
    "sin_memoria = rdd.map(transformation).filter(lambda x: x > 10).collect()\n",
    "print(\"Tiempo sin memoria:\", time.time() - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/06 18:59:30 WARN TaskSetManager: Stage 36 contains a task of very large size (9908 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con memoria: 2.890392303466797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tiempo con memoria\n",
    "inicio = time.time()\n",
    "con_memoria = rdd.map(transformation).filter(lambda x: x > 10).cache()\n",
    "result1 = con_memoria.collect()\n",
    "print(\"Con memoria:\", time.time() - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución con memoria: 0.053607940673828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/06 18:59:37 WARN TaskSetManager: Stage 37 contains a task of very large size (9908 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "# Repetir la misma operación\n",
    "inicio = time.time()\n",
    "result2 = con_memoria.collect()\n",
    "print(\"Tiempo de ejecución con memoria:\", time.time() - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros resultados sin memoria: [16, 20, 20, 12, 20, 20, 12, 15, 12, 12]\n",
      "Primeros resultados con memoria: [16, 20, 20, 12, 20, 20, 12, 15, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los primeros resultados\n",
    "print(\"Primeros resultados sin memoria:\", result1[:10])\n",
    "print(\"Primeros resultados con memoria:\", result2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 9, 12, 15]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistir en memoria y disco\n",
    "rdd_transformado = sc.parallelize([1, 2, 3, 4, 5]).map(lambda x: x * 3)\n",
    "rdd_transformado.persist(StorageLevel.MEMORY_AND_DISK).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la memoria antes de anular la persistencia: True\n",
      "Estado de la memoria después de anular la ppersistencia: False\n"
     ]
    }
   ],
   "source": [
    "# Comprobación del estado de memoria\n",
    "is_cached_before = con_memoria.is_cached\n",
    "con_memoria.unpersist()\n",
    "is_cached_after = con_memoria.is_cached\n",
    "\n",
    "print(\"Estado de la memoria antes de anular la persistencia:\",\n",
    "    is_cached_before)\n",
    "print(\"Estado de la memoria después de anular la ppersistencia:\",\n",
    "    is_cached_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de particiones (RDD simple): 1\n",
      "Número de particiones (RDD grande): 1\n",
      "Número de particiones después de reparticionar: 4\n",
      "Número de particiones después de reducir: 2\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de particiones\n",
    "rdd_simple = sc.parallelize([1, 2, 3, 4, 5])\n",
    "print(\"Número de particiones (RDD simple):\", rdd_simple.getNumPartitions())\n",
    "\n",
    "rdd_grande = sc.parallelize(datos)\n",
    "print(\"Número de particiones (RDD grande):\", rdd_grande.getNumPartitions())\n",
    "\n",
    "rdd_reparticionado = rdd_simple.repartition(4)\n",
    "print(\"Número de particiones después de reparticionar:\",\n",
    "    rdd_reparticionado.getNumPartitions())\n",
    "\n",
    "rdd_reducido = rdd_reparticionado.coalesce(2)\n",
    "print(\"Número de particiones después de reducir:\",\n",
    "    rdd_reducido.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Núcleos de procesamiento disponibles en el sistema: 20\n"
     ]
    }
   ],
   "source": [
    "# Contar núcleos de procesamiento disponibles\n",
    "print(\"Núcleos de procesamiento disponibles en el sistema:\",\n",
    "    multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de núcleos de Spark: 10\n"
     ]
    }
   ],
   "source": [
    "# Número de núcleos de Spark asociado al contexto\n",
    "print(\"Número de núcleos de Spark:\", sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de elementos en RDD: 5\n",
      "Primeros 3 elementos: [1, 2, 3]\n",
      "Reducción con división: 0.008333333333333333\n",
      "Reducción con mínimo: 1\n"
     ]
    }
   ],
   "source": [
    "# Operaciones en RDD\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "print(\"Conteo de elementos en RDD:\", rdd.count())\n",
    "print(\"Primeros 3 elementos:\", rdd.take(3))\n",
    "print(\"Reducción con división:\", rdd.reduce(lambda x, y: x / y))\n",
    "print(\"Reducción con mínimo:\", rdd.reduce(lambda x, y: min(x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda a archivo de texto\n",
    "destino = \"content/guardado.txt\"\n",
    "rdd.saveAsTextFile(destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados desde archivo: ['5', '1', '3', '2', '4']\n"
     ]
    }
   ],
   "source": [
    "# Carga desde archivo de texto\n",
    "cargado = sc.textFile(destino)\n",
    "print(\"Datos cargados desde archivo:\", cargado.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: History of free and open-source software\n",
      "Contenido: The history of free and open-source software begins at the advent of computer\n",
      "software in the early half of the 20th century. In the 1950s and 1960s, computer\n",
      "operating software and compilers were del...\n",
      "\n",
      "Título: Federal State Statistics Service (Russia)\n",
      "Contenido: The Federal State Statistics Service (‹See Tfd›Russian: Федеральная служба\n",
      "государственной статистики, romanized: Federalnaya sluzhba gosudarstvennoy\n",
      "statistiki, abbreviated as Rosstat) is the governm...\n",
      "\n",
      "Título: Culture of North Korea\n",
      "Contenido: The contemporary culture of North Korea is based on traditional Korean culture,\n",
      "but has developed since the division of Korea in 1945. Juche, officially the\n",
      "Juche idea, is the state ideology of North ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def contenido_wikipedia(titulo):\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": titulo,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True\n",
    "    }\n",
    "    response = requests.get(url, params=params).json()\n",
    "    pages = response[\"query\"][\"pages\"]\n",
    "    return list(pages.values())[0].get(\"extract\", \"\")\n",
    "\n",
    "articulos = [\"History of free and open-source software\",\n",
    "    \"Federal State Statistics Service (Russia)\", \"Culture of North Korea\"]\n",
    "rdd_articulos = sc.parallelize(articulos)\n",
    "rdd_contenido = rdd_articulos.map(lambda titulo: {\n",
    "    \"title\": titulo, \n",
    "    \"content\": contenido_wikipedia(titulo)\n",
    "})\n",
    "\n",
    "resultado = rdd_contenido.collect()\n",
    "for article in resultado:\n",
    "    title = article['title']\n",
    "    content = article['content'][:200] + '...'\n",
    "    wrapped_content = textwrap.fill(content, width=80)\n",
    "    print(f\"Título: {title}\\nContenido: {wrapped_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detener el contexto de Spark\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
